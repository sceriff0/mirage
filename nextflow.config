/*
========================================================================================
    MIRAGE WSI Processing Pipeline - Main Configuration
========================================================================================
    Author: mirage team
    Version: 0.1.0
========================================================================================
*/

/*
========================================================================================
    Plugins
========================================================================================
*/

plugins {
    id 'nf-boost'
}

// Include modular configurations
includeConfig 'conf/base.config'
includeConfig 'conf/modules.config'

// Pipeline metadata
manifest {
    name            = 'mirage'
    description     = 'WSI processing pipeline (preprocessing, registration, segmentation, quantification, phenotyping)'
    author          = 'mirage team'
    version         = '0.1.0'
    nextflowVersion = '>=25.04.0'
    mainScript      = 'main.nf'
}


/*
========================================================================================
    Resource Limit Functions
========================================================================================
*/

// Function to ensure resources don't exceed maximum limits
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "WARNING: Max memory '${params.max_memory}' is not valid"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "WARNING: Max time '${params.max_time}' is not valid"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min(obj, params.max_cpus as int)
        } catch (all) {
            println "WARNING: Max cpus '${params.max_cpus}' is not valid"
            return obj
        }
    }
}

/*
========================================================================================
    Pipeline Parameters
========================================================================================
*/

params {
    // Input/output
    input              = ''
    outdir             = "/hpcnfs/techunits/imaging/work/ATTEND/full_analysis/valis_high"

    // Workflow control
    step           = 'preprocessing' // preprocessing | registration | postprocessing
    dry_run        = false
    debug_channels = false

    // Cluster options
    slurm_partition = null
    slurm_account   = null
    slurm_qos       = null
    gpu_type        = 'nvidia_h200:1'

    // Preprocessing
    preproc_tile_size         = 1950
    preproc_skip_dapi         = true
    preproc_autotune          = false
    preproc_n_iter            = 100
    preproc_pool_workers      = 4
    preproc_overlap           = 0
    preproc_no_darkfield      = false
    preprocess_qc_scale_factor = 0.25

    // Registration (common)
    registration_method  = 'valis' // valis | valis_pairs | gpu | cpu | cpu_tiled
    allow_auto_reference = false
    padding              = false
    pad_mode             = 'constant'
    skip_registration_qc = false
    qc_scale_factor      = 0.25
    enable_feature_error = false
    feature_detector     = 'superpoint'
    feature_max_dim      = 1024
    feature_n_features   = 5000

    // Registration (VALIS)
    reg_reference_markers      = ['DAPI', 'FITC']
    memory_mode                = 'high'
    reg_micro_reg_fraction     = 0.125
    reg_max_image_dim          = 4000
    skip_micro_registration    = true
    reg_parallel_warping       = false
    reg_n_workers              = 8
    reg_use_tiled_registration = true
    reg_tile_size              = 2048

    // Registration (GPU pairwise)
    gpu_reg_affine_crop_size = 10000
    gpu_reg_diffeo_crop_size = 2000
    gpu_reg_overlap_percent  = 40.0
    gpu_reg_n_features       = 5000
    gpu_reg_n_workers        = 8
    gpu_reg_opt_tol          = 1e-6
    gpu_reg_inv_tol          = 1e-6

    // Registration (CPU pairwise / tiled)
    cpu_reg_affine_crop_size = 10000
    cpu_reg_diffeo_crop_size = 2000
    cpu_reg_overlap_percent  = 40.0
    cpu_reg_n_features       = 5000
    cpu_reg_opt_tol          = 1e-6
    cpu_reg_inv_tol          = 1e-6

    // Segmentation
    seg_gpu                = true
    seg_pmin               = 1.0
    seg_pmax               = 99.8
    seg_n_tiles_y          = 16
    seg_n_tiles_x          = 16
    seg_expand_distance    = 10
    segmentation_model_dir = '/hpcnfs/scratch/P_DIMA_ATTEND/models/'
    segmentation_model     = 'stardist_full_e200_lr00001_aug1_seed10_es50p0.001_rlr0.5p50'

    // Quantification
    quant_min_area = 10

    // Phenotyping
    phenotype_config         = null
    pheno_quality_percentile = 95
    pheno_noise_percentile   = 5

    // Image and pyramid output
    pixel_size          = 0.325
    tilex               = 512
    tiley               = 512
    pyramid_resolutions = 3
    pyramid_scale       = 2
    compression         = 'lzw'
    publish_dir_mode    = 'copy'

    // Limits and tracing
    max_memory   = '700.GB'
    max_cpus     = 64
    max_time     = '240.h'
    enable_trace = true
    trace_dir    = '.trace'
}

/*
========================================================================================
    Container Images
========================================================================================
*/

params.container = [
    preprocess:     'docker://bolt3x/attend_image_analysis:preprocess',
    registration:   'docker://cdgatenbee/valis-wsi:1.0.0',
    register_gpu:   'docker://bolt3x/attend_image_analysis:debug_diffeo', 
    merge:          'docker://bolt3x/attend_image_analysis:merge',
    segmentation:   'docker://bolt3x/attend_image_analysis:segmentation_gpu',
    quantification: 'docker://bolt3x/attend_image_analysis:quantification_gpu'
]

/*
========================================================================================
    Execution Profiles
========================================================================================
*/

profiles {
    // Default: SLURM execution with Singularity containers
    standard {
        process.executor = 'slurm'
        process.queue    = params.slurm_partition
        process.container = "alech00/attend_image_analysis:v2.1"

        singularity.enabled    = true
        singularity.autoMounts = true
        singularity.runOptions = '--writable-tmpfs --bind /hpcnfs/scratch/P_DIMA_ATTEND/models --bind /hpcnfs/home/ieo7660/.deepcell/models --bind /hpcnfs/home/ieo7660/.cupy'
        docker.enabled         = false

        process.clusterOptions = {
            def opts = []
            if (params.slurm_account && params.slurm_account != '') opts << "--account=${params.slurm_account}"
            if (params.slurm_qos && params.slurm_qos != '')         opts << "--qos=${params.slurm_qos}"
            return opts ? opts.join(' ') : null
        }
    }

    // SLURM with Singularity containers (alias for standard)
    slurm {
        process.executor = 'slurm'
        process.queue    = params.slurm_partition
        process.container = "alech00/attend_image_analysis:v2.1"

        singularity.enabled    = true
        singularity.autoMounts = true
        singularity.runOptions = '--writable-tmpfs --bind /hpcnfs/scratch/P_DIMA_ATTEND/models --bind /hpcnfs/home/ieo7660/.deepcell/models'
        docker.enabled         = false

        process.clusterOptions = {
            def opts = []
            if (params.slurm_account && params.slurm_account != '') opts << "--account=${params.slurm_account}"
            if (params.slurm_qos && params.slurm_qos != '')         opts << "--qos=${params.slurm_qos}"
            return opts ? opts.join(' ') : null
        }
    }

    // Test profile (small dataset validation)
    test {
        params.test = true
        includeConfig 'conf/test.config'
    }

    // Local development (no SLURM)
    local {
        process.executor = 'local'
        process.cpus     = 4
        process.memory   = '16.GB'
    }

    // Docker (local development with containers)
    docker {
        process.executor  = 'local'
        docker.enabled    = true
        docker.runOptions = '-u $(id -u):$(id -g)'
        singularity.enabled = false
    }

    // Singularity profile (for HPC without SLURM executor)
    singularity {
        process.executor       = 'slurm'
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
    }
}

/*
========================================================================================
    Nextflow Tower (optional monitoring)
========================================================================================
*/

tower {
    workspaceId = '61664385669434'
    enabled  = false
    endpoint = 'https://seqera.ieo.it/api'
}

/*
========================================================================================
    Execution Tracing (Optional)
========================================================================================
*/

trace {
    enabled   = params.enable_trace
    file      = "${params.trace_dir}/trace.txt"
    fields    = 'task_id,process,tag,name,status,exit,submit,start,complete,duration,realtime,%cpu,cpus,memory,peak_rss,peak_vmem,rchar,wchar'
    overwrite = true
}

report {
    enabled   = params.enable_trace
    file      = "${params.trace_dir}/report.html"
    overwrite = true
}

timeline {
    enabled   = params.enable_trace
    file      = "${params.trace_dir}/timeline.html"
    overwrite = true
}

boost {
    cleanup = true
}

process {
    stageInMode = 'link'
}
